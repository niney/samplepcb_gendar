# Part Number Extractor - Transformer-based NER for PCB BOM Data

Transformer ê¸°ë°˜ NER(Named Entity Recognition) ëª¨ë¸ì„ í™œìš©í•˜ì—¬ PCB BOM ë°ì´í„°ì—ì„œ Part Numberë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ë¡œì»¬ ê°œë°œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### í•µì‹¬ ê¸°ëŠ¥
- âœ… í—¤ë” ì •ë³´ ì—†ì´ Part Number ìë™ ì¶”ì¶œ
- âœ… Part Numberê°€ ëœë¤í•œ ì—´ì— ìœ„ì¹˜í•´ë„ ì •í™•í•˜ê²Œ ì¸ì‹
- âœ… 95% ì´ìƒì˜ ë†’ì€ ì •í™•ë„ ëª©í‘œ
- âœ… ë¡œì»¬ PCì—ì„œ í•™ìŠµ ë° ì¶”ë¡  ê°€ëŠ¥
- âœ… ì‚¬ìš©ì ì¹œí™”ì ì¸ ëŒ€í™”í˜• CLI ë„êµ¬

### ê¸°ìˆ  ìŠ¤íƒ
- **Python 3.9+** with venv (ê°€ìƒí™˜ê²½)
- **PyTorch 2.0+** - Deep Learning í”„ë ˆì„ì›Œí¬
- **Transformers (Hugging Face)** - BERT/RoBERTa/DeBERTa ëª¨ë¸
- **FastAPI** - API ì„œë²„ (ì„ íƒì )
- **pandas, numpy** - ë°ì´í„° ì²˜ë¦¬

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# í”„ë¡œì íŠ¸ í´ë¡  ë˜ëŠ” ë‹¤ìš´ë¡œë“œ
cd part-number-extractor

# âš ï¸ ì¤‘ìš”: venv ê°€ìƒí™˜ê²½ ìƒì„± (í•„ìˆ˜!)
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# Windows (ëª…ë ¹ í”„ë¡¬í”„íŠ¸)
venv\Scripts\activate
# Windows (PowerShell)
venv\Scripts\Activate.ps1
# Linux/Mac
source venv/bin/activate

# (venv) í‘œì‹œ í™•ì¸ - ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤

# pip ì—…ê·¸ë ˆì´ë“œ
python -m pip install --upgrade pip

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# GPU ì‚¬ìš© ì‹œ (CUDA 11.8 ê¸°ì¤€)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 2. GPU í™•ì¸

```bash
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
part-number-extractor/
â”œâ”€â”€ data/                    # ë°ì´í„° ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ raw/                 # ì›ë³¸ BOM íŒŒì¼
â”‚   â”œâ”€â”€ processed/           # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”œâ”€â”€ train.json          # í•™ìŠµ ë°ì´í„°
â”‚   â”œâ”€â”€ val.json            # ê²€ì¦ ë°ì´í„°
â”‚   â””â”€â”€ test.json           # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚
â”œâ”€â”€ src/                     # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ data_preparation/   # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ preprocessor.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â””â”€â”€ augmentation.py
â”‚   â”œâ”€â”€ model/              # ëª¨ë¸ ì •ì˜
â”‚   â”‚   â””â”€â”€ ner_model.py
â”‚   â”œâ”€â”€ training/           # í•™ìŠµ ë¡œì§
â”‚   â”‚   â””â”€â”€ trainer.py
â”‚   â”œâ”€â”€ evaluation/         # í‰ê°€ ë©”íŠ¸ë¦­
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”œâ”€â”€ inference/          # ì¶”ë¡  ì—”ì§„
â”‚   â”‚   â””â”€â”€ predictor.py
â”‚   â””â”€â”€ utils/              # ìœ í‹¸ë¦¬í‹°
â”‚       â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ scripts/                # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ train.py           # í•™ìŠµ ì‹¤í–‰
â”‚   â”œâ”€â”€ predict.py         # ì¶”ë¡  ì‹¤í–‰
â”‚   â”œâ”€â”€ evaluate.py        # í‰ê°€ ì‹¤í–‰
â”‚   â”œâ”€â”€ interactive_label.py      # ëŒ€í™”í˜• ë¼ë²¨ë§
â”‚   â”œâ”€â”€ train_interactive.py      # ëŒ€í™”í˜• í•™ìŠµ ë§ˆë²•ì‚¬
â”‚   â””â”€â”€ predict_interactive.py    # ëŒ€í™”í˜• ì˜ˆì¸¡
â”‚
â”œâ”€â”€ configs/               # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ bert_base.yaml
â”‚   â”œâ”€â”€ roberta_base.yaml
â”‚   â””â”€â”€ deberta_v3.yaml
â”‚
â”œâ”€â”€ models/                # ì €ì¥ëœ ëª¨ë¸
â”œâ”€â”€ logs/                  # í•™ìŠµ ë¡œê·¸
â”œâ”€â”€ requirements.txt       # íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â””â”€â”€ README.md
```

---

## ğŸ“Š ë°ì´í„° ì¤€ë¹„

### ë°ì´í„° í¬ë§·

ë¼ë²¨ë§ëœ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```json
[
  {
    "row_id": "001",
    "cells": [
      "C29 C33 C34",
      "CC0402KRX7R9BB102",
      "CAP CER 1000PF 50V X7R 0402",
      "9",
      "Yageo",
      "1005"
    ],
    "labels": [
      "REFERENCE",
      "PART_NUMBER",
      "DESCRIPTION",
      "QUANTITY",
      "MANUFACTURER",
      "PACKAGE"
    ]
  }
]
```

### ëŒ€í™”í˜• ë¼ë²¨ë§ ë„êµ¬ ì‚¬ìš©

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í•„ìˆ˜!
python scripts/interactive_label.py --input data/raw/bom_sample.csv --output data/labeled.json
```

ì´ ë„êµ¬ëŠ”:
- ê° ì…€ì— ëŒ€í•´ ëŒ€í™”í˜•ìœ¼ë¡œ ë¼ë²¨ ì„ íƒ
- ì§„í–‰ ìƒí™© ìë™ ì €ì¥ (10ê°œ í–‰ë§ˆë‹¤)
- ì–¸ì œë“ ì§€ ì¤‘ë‹¨ í›„ ì¬ê°œ ê°€ëŠ¥

---

## ğŸ“ ëª¨ë¸ í•™ìŠµ

### ë°©ë²• 1: ëŒ€í™”í˜• ë§ˆë²•ì‚¬ ì‚¬ìš© (ì¶”ì²œ)

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í•„ìˆ˜!
python scripts/train_interactive.py
```

ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ë”°ë¼ ì„¤ì •í•˜ë©´ ìë™ìœ¼ë¡œ í•™ìŠµì´ ì‹œì‘ë©ë‹ˆë‹¤.

### ë°©ë²• 2: ì»¤ë§¨ë“œë¼ì¸ ì§ì ‘ ì‹¤í–‰

```bash
# ê¸°ë³¸ í•™ìŠµ (BERT-base)
python scripts/train.py \
    --config configs/bert_base.yaml \
    --train_data data/train.json \
    --val_data data/val.json \
    --output_dir models/bert_checkpoint

# RoBERTa ëª¨ë¸ë¡œ í•™ìŠµ
python scripts/train.py \
    --config configs/roberta_base.yaml \
    --train_data data/train.json \
    --val_data data/val.json \
    --output_dir models/roberta_checkpoint

# ì»¤ìŠ¤í…€ ì„¤ì •
python scripts/train.py \
    --model_name bert-base-uncased \
    --epochs 15 \
    --batch_size 8 \
    --train_data data/train.json \
    --val_data data/val.json \
    --output_dir models/custom_model
```

---

## ğŸ”® Part Number ì¶”ì¶œ (ì¶”ë¡ )

### ë°©ë²• 1: ëŒ€í™”í˜• ì˜ˆì¸¡ ë„êµ¬ (ì¶”ì²œ)

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í•„ìˆ˜!
python scripts/predict_interactive.py --model_path models/bert_checkpoint/final_model
```

ì´ ë„êµ¬ëŠ”:
- ë‹¨ì¼ í–‰ ì…ë ¥ ëª¨ë“œ: ì¦‰ì‹œ ê²°ê³¼ í™•ì¸
- íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ: ë°°ì¹˜ ì²˜ë¦¬ ë° í†µê³„ ì œê³µ

### ë°©ë²• 2: ì»¤ë§¨ë“œë¼ì¸ ì§ì ‘ ì‹¤í–‰

```bash
# CSV íŒŒì¼ ì²˜ë¦¬
python scripts/predict.py \
    --model_path models/bert_checkpoint/final_model \
    --input_file data/new_bom.csv \
    --output_file results/predictions.csv \
    --confidence_threshold 0.8

# Excel íŒŒì¼ ì²˜ë¦¬
python scripts/predict.py \
    --model_path models/bert_checkpoint/final_model \
    --input_file data/new_bom.xlsx \
    --output_file results/predictions.xlsx \
    --confidence_threshold 0.7
```

### ì¶œë ¥ ê²°ê³¼

ê²°ê³¼ íŒŒì¼ì—ëŠ” ë‹¤ìŒ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤:
- `predicted_part_number`: ì¶”ì¶œëœ Part Number
- `confidence`: ì‹ ë¢°ë„ ì ìˆ˜ (0-1)
- `cell_index`: Part Numberê°€ ìˆëŠ” ì—´ ì¸ë±ìŠ¤
- `needs_review`: ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ë¯¸ë§Œì¸ ê²½ìš° True

---

## ğŸ“ˆ ëª¨ë¸ í‰ê°€

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í•„ìˆ˜!
python scripts/evaluate.py \
    --model_path models/bert_checkpoint/final_model \
    --test_data data/test.json \
    --output_dir evaluation_results
```

í‰ê°€ ì§€í‘œ:
- **F1 Score**: í† í° ë ˆë²¨ NER ì„±ëŠ¥
- **Precision & Recall**: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨
- **Part Number Accuracy**: ì‹¤ì œ Part Number ì¶”ì¶œ ì •í™•ë„

---

## ğŸ› ï¸ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

| ëª¨ë¸ | ì†ë„ | ì •í™•ë„ | GPU ë©”ëª¨ë¦¬ | ì¶”ì²œ ìš©ë„ |
|------|------|--------|-----------|----------|
| **BERT-base** | âš¡âš¡âš¡ | 90-93% | 4GB | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… |
| **RoBERTa-base** | âš¡âš¡ | 93-95% | 6GB | ê· í˜•ì¡íŒ ì„±ëŠ¥ |
| **DeBERTa-v3-base** | âš¡ | 95-97% | 8GB | ìµœê³  ì •í™•ë„ |

---

## ğŸ’» í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ì‚¬ì–‘
- CPU: Intel i5 ì´ìƒ
- RAM: 16GB (ìµœì†Œ 8GB)
- GPU: NVIDIA GTX 1060 6GB ì´ìƒ (CUDA ì§€ì›)
- Storage: SSD 20GB

### ê¶Œì¥ ì‚¬ì–‘
- CPU: Intel i7/i9 or AMD Ryzen 7/9
- RAM: 32GB
- GPU: NVIDIA RTX 3060 12GB ì´ìƒ
- Storage: NVMe SSD 50GB

---

## ğŸ“ ë°ì´í„° ì¦ê°•

```python
from src.data_preparation.augmentation import BOMDataAugmenter
from src.data_preparation.data_loader import load_bom_data, save_bom_data

# ë°ì´í„° ë¡œë“œ
data = load_bom_data('data/train.json')

# ì¦ê°•ê¸° ì´ˆê¸°í™”
augmenter = BOMDataAugmenter()

# ë°ì´í„° ì¦ê°• (1000ê°œ -> 5000ê°œ)
augmented_data = augmenter.augment_dataset(
    data,
    target_size=5000,
    methods=['shuffle', 'noise', 'format']
)

# ì €ì¥
save_bom_data(augmented_data, 'data/train_augmented.json')
```

---

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ì»¤ìŠ¤í…€ ëª¨ë¸ í•™ìŠµ

```python
from transformers import AutoTokenizer
from src.model.ner_model import create_model
from src.training.trainer import train_model
from src.data_preparation.data_loader import BOMDataset, load_bom_data
from src.data_preparation.preprocessor import BOMDataPreprocessor
from src.evaluation.metrics import compute_metrics

# ë°ì´í„° ë¡œë“œ
train_data = load_bom_data('data/train.json')
val_data = load_bom_data('data/val.json')

# í† í¬ë‚˜ì´ì € ë° ì „ì²˜ë¦¬
tokenizer = AutoTokenizer.from_pretrained('roberta-base')
preprocessor = BOMDataPreprocessor(tokenizer)

# ë°ì´í„°ì…‹ ìƒì„±
train_dataset = BOMDataset(train_data, preprocessor)
val_dataset = BOMDataset(val_data, preprocessor)

# ëª¨ë¸ ìƒì„±
model = create_model('roberta-base', num_labels=3)

# í•™ìŠµ
trainer = train_model(
    model,
    train_dataset,
    val_dataset,
    compute_metrics,
    output_dir='models/my_model'
)
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ê°€ìƒí™˜ê²½ ë¬¸ì œ

```bash
# ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°
# í”„ë¡¬í”„íŠ¸ì— (venv)ê°€ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

# ê°€ìƒí™˜ê²½ ë¹„í™œì„±í™”
deactivate
```

### CUDA ì—ëŸ¬

```bash
# CUDA ë²„ì „ í™•ì¸
python -c "import torch; print(torch.version.cuda)"

# CUDA ì‚¬ìš© ë¶ˆê°€ ì‹œ CPUë¡œ í•™ìŠµ
# configs/*.yaml íŒŒì¼ì—ì„œ fp16: false ë¡œ ì„¤ì •
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# batch_size ì¤„ì´ê¸°
python scripts/train.py --batch_size 8

# gradient_accumulation ì‚¬ìš© (ì„¤ì • íŒŒì¼ì—ì„œ)
gradient_accumulation_steps: 4
```

---

## ğŸ“Š ì„±ê³µ ì§€í‘œ (KPI)

### ëª¨ë¸ ì„±ëŠ¥
- âœ… Part Number ì¶”ì¶œ ì •í™•ë„: **95% ì´ìƒ**
- âœ… Token-level F1 Score: **0.93 ì´ìƒ**
- âœ… False Positive Rate: **5% ì´í•˜**

### ì‹œìŠ¤í…œ ì„±ëŠ¥
- âœ… GPU ì¶”ë¡  ì‹œê°„: **<100ms** (ë‹¨ì¼ í–‰)
- âœ… CPU ì¶”ë¡  ì‹œê°„: **<500ms** (ë‹¨ì¼ í–‰)
- âœ… ë°°ì¹˜ ì²˜ë¦¬ëŸ‰: **500-1,000 rows/ì´ˆ** (GPU)

---

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- [ë°ì´í„° ì¤€ë¹„ ê°€ì´ë“œ](docs/data_preparation.md)
- [ëª¨ë¸ í•™ìŠµ ê°€ì´ë“œ](docs/training_guide.md)
- [API ë¬¸ì„œ](docs/api_documentation.md)

---

## ğŸ¤ ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ëŠ” ë¡œì»¬ ê°œë°œìš©ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê°œì„  ì‚¬í•­ì´ë‚˜ ë²„ê·¸ ë¦¬í¬íŠ¸ëŠ” ì´ìŠˆë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”.

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

---

## ğŸ™ ê°ì‚¬ì˜ ë§

- Hugging Face Transformers
- PyTorch
- seqeval

---

## ğŸ“§ ë¬¸ì˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜: [your-email@example.com]

---

**âš ï¸ ì¤‘ìš”í•œ ì£¼ì˜ì‚¬í•­:**

1. **ê°€ìƒí™˜ê²½ ì‚¬ìš©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤!** ëª¨ë“  ì‘ì—… ì „ì— `venv` í™œì„±í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”.
2. í„°ë¯¸ë„ì„ ìƒˆë¡œ ì—´ ë•Œë§ˆë‹¤ ê°€ìƒí™˜ê²½ì„ ì¬í™œì„±í™”í•´ì•¼ í•©ë‹ˆë‹¤.
3. ëŒ€ê·œëª¨ ëª¨ë¸ í•™ìŠµ ì‹œ ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ì„ í™•ë³´í•˜ì„¸ìš”.
4. GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ê²½ìš° batch_sizeë¥¼ ì¤„ì´ì„¸ìš”.

**Happy Extracting! ğŸš€**
